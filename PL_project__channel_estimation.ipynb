{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "nsSKN4oPXsG_",
        "outputId": "ee7eeb8c-e847-4219-ceca-d9ae592635f5"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/gdrive/My Drive/PL project"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "bVjzIwxGX_zm",
        "outputId": "37441c82-9b64-4c1c-80e0-3f93e020e21a"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/My Drive/PL project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "IVc8UYJpXs75",
        "outputId": "d57487e8-0bea-4a2b-cacc-91821a76b2b2"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "My_noisy_H_12.mat  My_noisy_H_22.mat  Perfect_H_40000.mat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "xl1URzjzUPCF"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import math\n",
        "from scipy.io import loadmat # to load .mat file\n",
        "import matplotlib.pyplot as plt # to plot figure\n",
        "from scipy import interpolate "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def interpolation(noisy , SNR , Number_of_pilot , interp):\n",
        "    noisy_image = np.zeros((len(noisy),72,14,2))\n",
        "\n",
        "    noisy_image[:,:,:,0] = np.real(noisy) \n",
        "\n",
        "    noisy_image[:,:,:,1] = np.imag(noisy)\n",
        "\n",
        "\n",
        "    if (Number_of_pilot == 48):\n",
        "        idx = [14*i for i in range(1, 72,6)]+[4+14*(i) for i in range(4, 72,6)]+[7+14*(i) for i in range(1, 72,6)]+[11+14*(i) for i in range(4, 72,6)]\n",
        "    elif (Number_of_pilot == 16):\n",
        "        idx= [4+14*(i) for i in range(1, 72,9)]+[9+14*(i) for i in range(4, 72,9)]\n",
        "    elif (Number_of_pilot == 24):\n",
        "        idx = [14*i for i in range(1,72,9)]+ [6+14*i for i in range(4,72,9)]+ [11+14*i for i in range(1,72,9)]\n",
        "    elif (Number_of_pilot == 8):\n",
        "      idx = [4+14*(i) for  i in range(5,72,18)]+[9+14*(i) for i in range(8,72,18)]\n",
        "    elif (Number_of_pilot == 36):\n",
        "      idx = [14*(i) for  i in range(1,72,6)]+[6+14*(i) for i in range(4,72,6)] + [11+14*i for i in range(1,72,6)]\n",
        "\n",
        "\n",
        "\n",
        "    r = [x//14 for x in idx]\n",
        "    c = [x%14 for x in idx]\n",
        "\n",
        "\n",
        "\n",
        "    interp_noisy = np.zeros((len(noisy),72,14,2))\n",
        "\n",
        "    for i in range(len(noisy)):\n",
        "        z = [noisy_image[i,j,k,0] for j,k in zip(r,c)]\n",
        "        if(interp == 'rbf'):\n",
        "            f = interpolate.Rbf(np.array(r).astype(float), np.array(c).astype(float), z,function='gaussian')\n",
        "            X , Y = np.meshgrid(range(72),range(14))\n",
        "            z_intp = f(X, Y)\n",
        "            interp_noisy[i,:,:,0] = z_intp.T\n",
        "        elif(interp == 'spline'):\n",
        "            tck = interpolate.bisplrep(np.array(r).astype(float), np.array(c).astype(float), z)\n",
        "            z_intp = interpolate.bisplev(range(72),range(14),tck)\n",
        "            interp_noisy[i,:,:,0] = z_intp\n",
        "        z = [noisy_image[i,j,k,1] for j,k in zip(r,c)]\n",
        "        if(interp == 'rbf'):\n",
        "            f = interpolate.Rbf(np.array(r).astype(float), np.array(c).astype(float), z,function='gaussian')\n",
        "            X , Y = np.meshgrid(range(72),range(14))\n",
        "            z_intp = f(X, Y)\n",
        "            interp_noisy[i,:,:,1] = z_intp.T\n",
        "        elif(interp == 'spline'):\n",
        "            tck = interpolate.bisplrep(np.array(r).astype(float), np.array(c).astype(float), z)\n",
        "            z_intp = interpolate.bisplev(range(72),range(14),tck)\n",
        "            interp_noisy[i,:,:,1] = z_intp\n",
        "\n",
        "\n",
        "    interp_noisy = np.concatenate((interp_noisy[:,:,:,0], interp_noisy[:,:,:,1]), axis=0).reshape(len(noisy)*2, 72, 14, 1)\n",
        "   \n",
        "    \n",
        "    return interp_noisy\n",
        "   "
      ],
      "metadata": {
        "id": "nDcbUHYObzba"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    idx = [14*i for i in range(1, 72,6)]+[4+14*(i) for i in range(4, 72,6)]+[7+14*(i) for i in range(1, 72,6)]+[11+14*(i) for i in range(4, 72,6)]\n",
        "    r = [x//14 for x in idx]#indexes of pilot locations\n",
        "    c = [x%14 for x in idx]\n",
        "    #f = interpolate.Rbf(np.array(r).astype(float), np.array(c).astype(float),z,function='gaussian')\n",
        "    for j,k in zip(r,c):\n",
        "      print(j,k)\n",
        "    print(idx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "guxew6zqa9OO",
        "outputId": "115114e0-5958-4d3f-cbd5-4e5f2701a236"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 0\n",
            "7 0\n",
            "13 0\n",
            "19 0\n",
            "25 0\n",
            "31 0\n",
            "37 0\n",
            "43 0\n",
            "49 0\n",
            "55 0\n",
            "61 0\n",
            "67 0\n",
            "4 4\n",
            "10 4\n",
            "16 4\n",
            "22 4\n",
            "28 4\n",
            "34 4\n",
            "40 4\n",
            "46 4\n",
            "52 4\n",
            "58 4\n",
            "64 4\n",
            "70 4\n",
            "1 7\n",
            "7 7\n",
            "13 7\n",
            "19 7\n",
            "25 7\n",
            "31 7\n",
            "37 7\n",
            "43 7\n",
            "49 7\n",
            "55 7\n",
            "61 7\n",
            "67 7\n",
            "4 11\n",
            "10 11\n",
            "16 11\n",
            "22 11\n",
            "28 11\n",
            "34 11\n",
            "40 11\n",
            "46 11\n",
            "52 11\n",
            "58 11\n",
            "64 11\n",
            "70 11\n",
            "[14, 98, 182, 266, 350, 434, 518, 602, 686, 770, 854, 938, 60, 144, 228, 312, 396, 480, 564, 648, 732, 816, 900, 984, 21, 105, 189, 273, 357, 441, 525, 609, 693, 777, 861, 945, 67, 151, 235, 319, 403, 487, 571, 655, 739, 823, 907, 991]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "channel_model = \"VehA\"\n",
        "SNR = 12\n",
        "Number_of_pilots = 48\n",
        "perfect = loadmat(\"Perfect_H_40000.mat\")['My_perfect_H']\n",
        "noisy_input = loadmat(\"My_noisy_H_12.mat\")['My_noisy_H']\n",
        "\n",
        "print(perfect.shape)\n",
        "print(noisy_input.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "_VKdCOVmV_fZ",
        "outputId": "2baf09c0-7668-47f2-8d88-0d021e3a2c8c"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(40000, 72, 14)\n",
            "(40000, 72, 14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "noisy_input = noisy_input[0:1000]\n",
        "perfect = perfect[0:1000]\n",
        "\n",
        "print(perfect.shape)\n",
        "print(noisy_input.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "xWRWddsqNoZH",
        "outputId": "fc4d403b-e8f6-4543-cf6f-1561e213e844"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1000, 72, 14)\n",
            "(1000, 72, 14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "interp_noisy = interpolation(noisy_input , SNR , Number_of_pilots , 'rbf')\n",
        "print(SNR,Number_of_pilots)"
      ],
      "metadata": {
        "id": "yMrof-wFWX01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "af70a348-6d31-4392-946f-c71dc82bb10b"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12 48\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "interp_noisy.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "l1skpYdUZUSF",
        "outputId": "835b495a-d5d1-400f-dd0b-b46b3a1e182b"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 72, 14, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "perfect_image = np.zeros((len(perfect),72,14,2))\n",
        "perfect_image[:,:,:,0] = np.real(perfect)\n",
        "perfect_image[:,:,:,1] = np.imag(perfect)\n",
        "perfect_image = np.concatenate((perfect_image[:,:,:,0], perfect_image[:,:,:,1]), axis=0).reshape(2*len(perfect), 72, 14, 1)"
      ],
      "metadata": {
        "id": "zcgZC54TaPtK"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "perfect_image.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "jfbqWJE1aqf8",
        "outputId": "c226d247-d676-4a7e-d678-7b32542a8cf1"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 72, 14, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idx_random = np.random.rand(len(perfect_image)) < (1/9)  \n",
        "train_data, train_label = interp_noisy[idx_random,:,:,:] , perfect_image[idx_random,:,:,:]\n",
        "val_data, val_label = interp_noisy[~idx_random,:,:,:] , perfect_image[~idx_random,:,:,:]    \n",
        "\n",
        "print(train_data.shape)\n",
        "print(val_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "hCLZsRGqf8QH",
        "outputId": "c15a3209-6e20-48da-d839-52dfb79b7d58"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(234, 72, 14, 1)\n",
            "(1766, 72, 14, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Input, BatchNormalization, Activation, Subtract\n",
        "from tensorflow.keras.models import Sequential,  Model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "def SRCNN_model():\n",
        "\n",
        "    input_shape = (72,14,1)\n",
        "    x = Input(shape = input_shape)\n",
        "    c1 = Conv2D( 64 , 9, activation = 'relu', padding='same')(x)\n",
        "    c2 = Conv2D( 32 , 1, activation = 'relu', padding='same')(c1)\n",
        "    c3 = Conv2D( 1 , 1,padding='same')(c2)\n",
        "    model = Model(inputs = x, outputs = c3)\n",
        "    ##compile\n",
        "    #adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-8) \n",
        "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_squared_error']) \n",
        "    return model\n",
        "def DNCNN_model ():\n",
        "  \n",
        "    inpt = Input(shape=(None,None,1))\n",
        "    # 1st layer, Conv+relu\n",
        "    x = Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), padding='same')(inpt)\n",
        "    x = Activation('relu')(x)\n",
        "    # 18 layers, Conv+BN+relu\n",
        "    for i in range(18):\n",
        "        x = Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), padding='same')(x)\n",
        "        x = BatchNormalization(axis=-1, epsilon=1e-3)(x)\n",
        "        x = Activation('relu')(x)   \n",
        "    # last layer, Conv\n",
        "    x = Conv2D(filters=1, kernel_size=(3,3), strides=(1,1), padding='same')(x)\n",
        "    x = Subtract()([inpt, x])   # input - noise\n",
        "    model = Model(inputs=inpt, outputs=x)\n",
        "    #adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-8) \n",
        "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_squared_error'])    \n",
        "    return model\n"
      ],
      "metadata": {
        "id": "6ms3DEKSh4fL"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "sr_model = SRCNN_model()\n",
        "sr_model.summary()\n",
        "history1 = sr_model.fit(train_data, train_label, validation_data=(val_data, val_label), shuffle=True, epochs= 100)\n"
      ],
      "metadata": {
        "id": "PQTQWaiCpReT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "23648be5-d503-40a9-f0c0-63baf498e012"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 72, 14, 1)]       0         \n",
            "                                                                 \n",
            " conv2d_43 (Conv2D)          (None, 72, 14, 64)        5248      \n",
            "                                                                 \n",
            " conv2d_44 (Conv2D)          (None, 72, 14, 32)        2080      \n",
            "                                                                 \n",
            " conv2d_45 (Conv2D)          (None, 72, 14, 1)         33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,361\n",
            "Trainable params: 7,361\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "8/8 [==============================] - 3s 317ms/step - loss: 0.2311 - mean_squared_error: 0.2311 - val_loss: 0.0551 - val_mean_squared_error: 0.0551\n",
            "Epoch 2/100\n",
            "8/8 [==============================] - 2s 280ms/step - loss: 0.0593 - mean_squared_error: 0.0593 - val_loss: 0.0515 - val_mean_squared_error: 0.0515\n",
            "Epoch 3/100\n",
            "8/8 [==============================] - 2s 275ms/step - loss: 0.0359 - mean_squared_error: 0.0359 - val_loss: 0.0353 - val_mean_squared_error: 0.0353\n",
            "Epoch 4/100\n",
            "8/8 [==============================] - 2s 277ms/step - loss: 0.0285 - mean_squared_error: 0.0285 - val_loss: 0.0296 - val_mean_squared_error: 0.0296\n",
            "Epoch 5/100\n",
            "8/8 [==============================] - 2s 279ms/step - loss: 0.0252 - mean_squared_error: 0.0252 - val_loss: 0.0256 - val_mean_squared_error: 0.0256\n",
            "Epoch 6/100\n",
            "8/8 [==============================] - 2s 275ms/step - loss: 0.0226 - mean_squared_error: 0.0226 - val_loss: 0.0232 - val_mean_squared_error: 0.0232\n",
            "Epoch 7/100\n",
            "8/8 [==============================] - 2s 279ms/step - loss: 0.0210 - mean_squared_error: 0.0210 - val_loss: 0.0215 - val_mean_squared_error: 0.0215\n",
            "Epoch 8/100\n",
            "8/8 [==============================] - 2s 275ms/step - loss: 0.0195 - mean_squared_error: 0.0195 - val_loss: 0.0201 - val_mean_squared_error: 0.0201\n",
            "Epoch 9/100\n",
            "8/8 [==============================] - 2s 275ms/step - loss: 0.0184 - mean_squared_error: 0.0184 - val_loss: 0.0189 - val_mean_squared_error: 0.0189\n",
            "Epoch 10/100\n",
            "8/8 [==============================] - 2s 276ms/step - loss: 0.0176 - mean_squared_error: 0.0176 - val_loss: 0.0184 - val_mean_squared_error: 0.0184\n",
            "Epoch 11/100\n",
            "8/8 [==============================] - 2s 277ms/step - loss: 0.0171 - mean_squared_error: 0.0171 - val_loss: 0.0178 - val_mean_squared_error: 0.0178\n",
            "Epoch 12/100\n",
            "8/8 [==============================] - 2s 279ms/step - loss: 0.0167 - mean_squared_error: 0.0167 - val_loss: 0.0174 - val_mean_squared_error: 0.0174\n",
            "Epoch 13/100\n",
            "8/8 [==============================] - 2s 278ms/step - loss: 0.0162 - mean_squared_error: 0.0162 - val_loss: 0.0169 - val_mean_squared_error: 0.0169\n",
            "Epoch 14/100\n",
            "8/8 [==============================] - 2s 276ms/step - loss: 0.0159 - mean_squared_error: 0.0159 - val_loss: 0.0167 - val_mean_squared_error: 0.0167\n",
            "Epoch 15/100\n",
            "8/8 [==============================] - 2s 275ms/step - loss: 0.0157 - mean_squared_error: 0.0157 - val_loss: 0.0164 - val_mean_squared_error: 0.0164\n",
            "Epoch 16/100\n",
            "8/8 [==============================] - 2s 275ms/step - loss: 0.0155 - mean_squared_error: 0.0155 - val_loss: 0.0162 - val_mean_squared_error: 0.0162\n",
            "Epoch 17/100\n",
            "8/8 [==============================] - 2s 277ms/step - loss: 0.0152 - mean_squared_error: 0.0152 - val_loss: 0.0159 - val_mean_squared_error: 0.0159\n",
            "Epoch 18/100\n",
            "8/8 [==============================] - 2s 276ms/step - loss: 0.0151 - mean_squared_error: 0.0151 - val_loss: 0.0157 - val_mean_squared_error: 0.0157\n",
            "Epoch 19/100\n",
            "8/8 [==============================] - 2s 275ms/step - loss: 0.0150 - mean_squared_error: 0.0150 - val_loss: 0.0155 - val_mean_squared_error: 0.0155\n",
            "Epoch 20/100\n",
            "8/8 [==============================] - 2s 276ms/step - loss: 0.0148 - mean_squared_error: 0.0148 - val_loss: 0.0155 - val_mean_squared_error: 0.0155\n",
            "Epoch 21/100\n",
            "8/8 [==============================] - 2s 275ms/step - loss: 0.0147 - mean_squared_error: 0.0147 - val_loss: 0.0153 - val_mean_squared_error: 0.0153\n",
            "Epoch 22/100\n",
            "8/8 [==============================] - 2s 274ms/step - loss: 0.0145 - mean_squared_error: 0.0145 - val_loss: 0.0153 - val_mean_squared_error: 0.0153\n",
            "Epoch 23/100\n",
            "8/8 [==============================] - 2s 277ms/step - loss: 0.0144 - mean_squared_error: 0.0144 - val_loss: 0.0152 - val_mean_squared_error: 0.0152\n",
            "Epoch 24/100\n",
            "8/8 [==============================] - 2s 275ms/step - loss: 0.0143 - mean_squared_error: 0.0143 - val_loss: 0.0150 - val_mean_squared_error: 0.0150\n",
            "Epoch 25/100\n",
            "8/8 [==============================] - 2s 274ms/step - loss: 0.0142 - mean_squared_error: 0.0142 - val_loss: 0.0147 - val_mean_squared_error: 0.0147\n",
            "Epoch 26/100\n",
            "8/8 [==============================] - 2s 273ms/step - loss: 0.0140 - mean_squared_error: 0.0140 - val_loss: 0.0146 - val_mean_squared_error: 0.0146\n",
            "Epoch 27/100\n",
            "8/8 [==============================] - 2s 277ms/step - loss: 0.0138 - mean_squared_error: 0.0138 - val_loss: 0.0144 - val_mean_squared_error: 0.0144\n",
            "Epoch 28/100\n",
            "8/8 [==============================] - 2s 276ms/step - loss: 0.0137 - mean_squared_error: 0.0137 - val_loss: 0.0143 - val_mean_squared_error: 0.0143\n",
            "Epoch 29/100\n",
            "8/8 [==============================] - 2s 273ms/step - loss: 0.0136 - mean_squared_error: 0.0136 - val_loss: 0.0144 - val_mean_squared_error: 0.0144\n",
            "Epoch 30/100\n",
            "8/8 [==============================] - 2s 278ms/step - loss: 0.0135 - mean_squared_error: 0.0135 - val_loss: 0.0142 - val_mean_squared_error: 0.0142\n",
            "Epoch 31/100\n",
            "8/8 [==============================] - 2s 279ms/step - loss: 0.0135 - mean_squared_error: 0.0135 - val_loss: 0.0140 - val_mean_squared_error: 0.0140\n",
            "Epoch 32/100\n",
            "8/8 [==============================] - 2s 275ms/step - loss: 0.0134 - mean_squared_error: 0.0134 - val_loss: 0.0140 - val_mean_squared_error: 0.0140\n",
            "Epoch 33/100\n",
            "8/8 [==============================] - 2s 279ms/step - loss: 0.0133 - mean_squared_error: 0.0133 - val_loss: 0.0139 - val_mean_squared_error: 0.0139\n",
            "Epoch 34/100\n",
            "8/8 [==============================] - 2s 280ms/step - loss: 0.0132 - mean_squared_error: 0.0132 - val_loss: 0.0142 - val_mean_squared_error: 0.0142\n",
            "Epoch 35/100\n",
            "8/8 [==============================] - 2s 277ms/step - loss: 0.0133 - mean_squared_error: 0.0133 - val_loss: 0.0138 - val_mean_squared_error: 0.0138\n",
            "Epoch 36/100\n",
            "8/8 [==============================] - 2s 276ms/step - loss: 0.0131 - mean_squared_error: 0.0131 - val_loss: 0.0137 - val_mean_squared_error: 0.0137\n",
            "Epoch 37/100\n",
            "8/8 [==============================] - 2s 275ms/step - loss: 0.0131 - mean_squared_error: 0.0131 - val_loss: 0.0137 - val_mean_squared_error: 0.0137\n",
            "Epoch 38/100\n",
            "8/8 [==============================] - 2s 281ms/step - loss: 0.0130 - mean_squared_error: 0.0130 - val_loss: 0.0136 - val_mean_squared_error: 0.0136\n",
            "Epoch 39/100\n",
            "8/8 [==============================] - 2s 281ms/step - loss: 0.0130 - mean_squared_error: 0.0130 - val_loss: 0.0136 - val_mean_squared_error: 0.0136\n",
            "Epoch 40/100\n",
            "8/8 [==============================] - 2s 280ms/step - loss: 0.0130 - mean_squared_error: 0.0130 - val_loss: 0.0136 - val_mean_squared_error: 0.0136\n",
            "Epoch 41/100\n",
            "8/8 [==============================] - 2s 276ms/step - loss: 0.0129 - mean_squared_error: 0.0129 - val_loss: 0.0135 - val_mean_squared_error: 0.0135\n",
            "Epoch 42/100\n",
            "8/8 [==============================] - 2s 279ms/step - loss: 0.0128 - mean_squared_error: 0.0128 - val_loss: 0.0135 - val_mean_squared_error: 0.0135\n",
            "Epoch 43/100\n",
            "8/8 [==============================] - 2s 280ms/step - loss: 0.0128 - mean_squared_error: 0.0128 - val_loss: 0.0133 - val_mean_squared_error: 0.0133\n",
            "Epoch 44/100\n",
            "8/8 [==============================] - 2s 277ms/step - loss: 0.0127 - mean_squared_error: 0.0127 - val_loss: 0.0135 - val_mean_squared_error: 0.0135\n",
            "Epoch 45/100\n",
            "8/8 [==============================] - 2s 278ms/step - loss: 0.0127 - mean_squared_error: 0.0127 - val_loss: 0.0133 - val_mean_squared_error: 0.0133\n",
            "Epoch 46/100\n",
            "8/8 [==============================] - 2s 277ms/step - loss: 0.0126 - mean_squared_error: 0.0126 - val_loss: 0.0132 - val_mean_squared_error: 0.0132\n",
            "Epoch 47/100\n",
            "8/8 [==============================] - 2s 277ms/step - loss: 0.0126 - mean_squared_error: 0.0126 - val_loss: 0.0134 - val_mean_squared_error: 0.0134\n",
            "Epoch 48/100\n",
            "8/8 [==============================] - 2s 278ms/step - loss: 0.0128 - mean_squared_error: 0.0128 - val_loss: 0.0138 - val_mean_squared_error: 0.0138\n",
            "Epoch 49/100\n",
            "8/8 [==============================] - 2s 274ms/step - loss: 0.0127 - mean_squared_error: 0.0127 - val_loss: 0.0130 - val_mean_squared_error: 0.0130\n",
            "Epoch 50/100\n",
            "8/8 [==============================] - 2s 276ms/step - loss: 0.0124 - mean_squared_error: 0.0124 - val_loss: 0.0131 - val_mean_squared_error: 0.0131\n",
            "Epoch 51/100\n",
            "8/8 [==============================] - 2s 281ms/step - loss: 0.0124 - mean_squared_error: 0.0124 - val_loss: 0.0129 - val_mean_squared_error: 0.0129\n",
            "Epoch 52/100\n",
            "8/8 [==============================] - 2s 277ms/step - loss: 0.0124 - mean_squared_error: 0.0124 - val_loss: 0.0131 - val_mean_squared_error: 0.0131\n",
            "Epoch 53/100\n",
            "8/8 [==============================] - 2s 280ms/step - loss: 0.0123 - mean_squared_error: 0.0123 - val_loss: 0.0130 - val_mean_squared_error: 0.0130\n",
            "Epoch 54/100\n",
            "8/8 [==============================] - 2s 282ms/step - loss: 0.0123 - mean_squared_error: 0.0123 - val_loss: 0.0128 - val_mean_squared_error: 0.0128\n",
            "Epoch 55/100\n",
            "8/8 [==============================] - 2s 281ms/step - loss: 0.0122 - mean_squared_error: 0.0122 - val_loss: 0.0128 - val_mean_squared_error: 0.0128\n",
            "Epoch 56/100\n",
            "8/8 [==============================] - 2s 282ms/step - loss: 0.0122 - mean_squared_error: 0.0122 - val_loss: 0.0128 - val_mean_squared_error: 0.0128\n",
            "Epoch 57/100\n",
            "8/8 [==============================] - 2s 282ms/step - loss: 0.0122 - mean_squared_error: 0.0122 - val_loss: 0.0127 - val_mean_squared_error: 0.0127\n",
            "Epoch 58/100\n",
            "8/8 [==============================] - 2s 279ms/step - loss: 0.0121 - mean_squared_error: 0.0121 - val_loss: 0.0130 - val_mean_squared_error: 0.0130\n",
            "Epoch 59/100\n",
            "8/8 [==============================] - 2s 282ms/step - loss: 0.0121 - mean_squared_error: 0.0121 - val_loss: 0.0127 - val_mean_squared_error: 0.0127\n",
            "Epoch 60/100\n",
            "8/8 [==============================] - 2s 282ms/step - loss: 0.0121 - mean_squared_error: 0.0121 - val_loss: 0.0127 - val_mean_squared_error: 0.0127\n",
            "Epoch 61/100\n",
            "8/8 [==============================] - 2s 280ms/step - loss: 0.0121 - mean_squared_error: 0.0121 - val_loss: 0.0128 - val_mean_squared_error: 0.0128\n",
            "Epoch 62/100\n",
            "8/8 [==============================] - 2s 284ms/step - loss: 0.0121 - mean_squared_error: 0.0121 - val_loss: 0.0126 - val_mean_squared_error: 0.0126\n",
            "Epoch 63/100\n",
            "8/8 [==============================] - 2s 282ms/step - loss: 0.0120 - mean_squared_error: 0.0120 - val_loss: 0.0124 - val_mean_squared_error: 0.0124\n",
            "Epoch 64/100\n",
            "8/8 [==============================] - 2s 280ms/step - loss: 0.0119 - mean_squared_error: 0.0119 - val_loss: 0.0125 - val_mean_squared_error: 0.0125\n",
            "Epoch 65/100\n",
            "8/8 [==============================] - 2s 286ms/step - loss: 0.0119 - mean_squared_error: 0.0119 - val_loss: 0.0125 - val_mean_squared_error: 0.0125\n",
            "Epoch 66/100\n",
            "8/8 [==============================] - 2s 282ms/step - loss: 0.0119 - mean_squared_error: 0.0119 - val_loss: 0.0127 - val_mean_squared_error: 0.0127\n",
            "Epoch 67/100\n",
            "8/8 [==============================] - 2s 284ms/step - loss: 0.0119 - mean_squared_error: 0.0119 - val_loss: 0.0125 - val_mean_squared_error: 0.0125\n",
            "Epoch 68/100\n",
            "8/8 [==============================] - 2s 284ms/step - loss: 0.0118 - mean_squared_error: 0.0118 - val_loss: 0.0123 - val_mean_squared_error: 0.0123\n",
            "Epoch 69/100\n",
            "8/8 [==============================] - 2s 285ms/step - loss: 0.0117 - mean_squared_error: 0.0117 - val_loss: 0.0122 - val_mean_squared_error: 0.0122\n",
            "Epoch 70/100\n",
            "8/8 [==============================] - 2s 281ms/step - loss: 0.0116 - mean_squared_error: 0.0116 - val_loss: 0.0124 - val_mean_squared_error: 0.0124\n",
            "Epoch 71/100\n",
            "8/8 [==============================] - 2s 284ms/step - loss: 0.0117 - mean_squared_error: 0.0117 - val_loss: 0.0125 - val_mean_squared_error: 0.0125\n",
            "Epoch 72/100\n",
            "8/8 [==============================] - 2s 275ms/step - loss: 0.0116 - mean_squared_error: 0.0116 - val_loss: 0.0124 - val_mean_squared_error: 0.0124\n",
            "Epoch 73/100\n",
            "8/8 [==============================] - 2s 282ms/step - loss: 0.0117 - mean_squared_error: 0.0117 - val_loss: 0.0120 - val_mean_squared_error: 0.0120\n",
            "Epoch 74/100\n",
            "8/8 [==============================] - 2s 285ms/step - loss: 0.0115 - mean_squared_error: 0.0115 - val_loss: 0.0119 - val_mean_squared_error: 0.0119\n",
            "Epoch 75/100\n",
            "8/8 [==============================] - 2s 278ms/step - loss: 0.0114 - mean_squared_error: 0.0114 - val_loss: 0.0122 - val_mean_squared_error: 0.0122\n",
            "Epoch 76/100\n",
            "8/8 [==============================] - 2s 278ms/step - loss: 0.0114 - mean_squared_error: 0.0114 - val_loss: 0.0119 - val_mean_squared_error: 0.0119\n",
            "Epoch 77/100\n",
            "8/8 [==============================] - 2s 278ms/step - loss: 0.0113 - mean_squared_error: 0.0113 - val_loss: 0.0118 - val_mean_squared_error: 0.0118\n",
            "Epoch 78/100\n",
            "8/8 [==============================] - 2s 280ms/step - loss: 0.0113 - mean_squared_error: 0.0113 - val_loss: 0.0119 - val_mean_squared_error: 0.0119\n",
            "Epoch 79/100\n",
            "8/8 [==============================] - 2s 287ms/step - loss: 0.0115 - mean_squared_error: 0.0115 - val_loss: 0.0125 - val_mean_squared_error: 0.0125\n",
            "Epoch 80/100\n",
            "8/8 [==============================] - 2s 280ms/step - loss: 0.0115 - mean_squared_error: 0.0115 - val_loss: 0.0126 - val_mean_squared_error: 0.0126\n",
            "Epoch 81/100\n",
            "8/8 [==============================] - 2s 280ms/step - loss: 0.0118 - mean_squared_error: 0.0118 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
            "Epoch 82/100\n",
            "8/8 [==============================] - 2s 284ms/step - loss: 0.0114 - mean_squared_error: 0.0114 - val_loss: 0.0118 - val_mean_squared_error: 0.0118\n",
            "Epoch 83/100\n",
            "8/8 [==============================] - 2s 278ms/step - loss: 0.0111 - mean_squared_error: 0.0111 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
            "Epoch 84/100\n",
            "8/8 [==============================] - 2s 284ms/step - loss: 0.0111 - mean_squared_error: 0.0111 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
            "Epoch 85/100\n",
            "8/8 [==============================] - 3s 425ms/step - loss: 0.0110 - mean_squared_error: 0.0110 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
            "Epoch 86/100\n",
            "8/8 [==============================] - 3s 399ms/step - loss: 0.0109 - mean_squared_error: 0.0109 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "Epoch 87/100\n",
            "8/8 [==============================] - 2s 282ms/step - loss: 0.0109 - mean_squared_error: 0.0109 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
            "Epoch 88/100\n",
            "8/8 [==============================] - 2s 281ms/step - loss: 0.0109 - mean_squared_error: 0.0109 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
            "Epoch 89/100\n",
            "8/8 [==============================] - 2s 282ms/step - loss: 0.0110 - mean_squared_error: 0.0110 - val_loss: 0.0118 - val_mean_squared_error: 0.0118\n",
            "Epoch 90/100\n",
            "8/8 [==============================] - 2s 283ms/step - loss: 0.0111 - mean_squared_error: 0.0111 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
            "Epoch 91/100\n",
            "8/8 [==============================] - 2s 279ms/step - loss: 0.0109 - mean_squared_error: 0.0109 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
            "Epoch 92/100\n",
            "8/8 [==============================] - 2s 279ms/step - loss: 0.0107 - mean_squared_error: 0.0107 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
            "Epoch 93/100\n",
            "8/8 [==============================] - 2s 286ms/step - loss: 0.0107 - mean_squared_error: 0.0107 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
            "Epoch 94/100\n",
            "8/8 [==============================] - 2s 281ms/step - loss: 0.0108 - mean_squared_error: 0.0108 - val_loss: 0.0112 - val_mean_squared_error: 0.0112\n",
            "Epoch 95/100\n",
            "8/8 [==============================] - 2s 281ms/step - loss: 0.0106 - mean_squared_error: 0.0106 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
            "Epoch 96/100\n",
            "8/8 [==============================] - 2s 280ms/step - loss: 0.0107 - mean_squared_error: 0.0107 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
            "Epoch 97/100\n",
            "8/8 [==============================] - 2s 278ms/step - loss: 0.0106 - mean_squared_error: 0.0106 - val_loss: 0.0112 - val_mean_squared_error: 0.0112\n",
            "Epoch 98/100\n",
            "8/8 [==============================] - 2s 283ms/step - loss: 0.0106 - mean_squared_error: 0.0106 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
            "Epoch 99/100\n",
            "8/8 [==============================] - 2s 280ms/step - loss: 0.0114 - mean_squared_error: 0.0114 - val_loss: 0.0112 - val_mean_squared_error: 0.0112\n",
            "Epoch 100/100\n",
            "8/8 [==============================] - 2s 284ms/step - loss: 0.0108 - mean_squared_error: 0.0108 - val_loss: 0.0112 - val_mean_squared_error: 0.0112\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(history1.history['loss'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "fzeI679LdkMN",
        "outputId": "4a4daf5c-dbd4-4f97-939e-4b6fbe00eab0"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.23106609284877777, 0.05931198596954346, 0.035894203931093216, 0.0284905843436718, 0.025232894346117973, 0.022615700960159302, 0.020995095372200012, 0.019474944099783897, 0.018382292240858078, 0.017645204439759254, 0.017086250707507133, 0.01669471710920334, 0.01622830145061016, 0.015925979241728783, 0.015651527792215347, 0.015529354102909565, 0.01519276387989521, 0.015129589475691319, 0.014956657774746418, 0.014776499941945076, 0.014704613946378231, 0.014485684223473072, 0.014360902830958366, 0.014317533932626247, 0.01415882259607315, 0.014021539129316807, 0.013837924227118492, 0.01373809203505516, 0.013645825907588005, 0.013516254723072052, 0.013511976227164268, 0.01338986773043871, 0.013301785103976727, 0.013228168711066246, 0.013295874930918217, 0.0131228594109416, 0.013093480840325356, 0.013033303432166576, 0.0129955243319273, 0.013020035810768604, 0.012899248860776424, 0.012764782644808292, 0.012771835550665855, 0.012676866725087166, 0.012695123441517353, 0.012632345780730247, 0.012628765776753426, 0.012778013944625854, 0.012652506120502949, 0.012448560446500778, 0.012372069992125034, 0.012381907552480698, 0.012335079722106457, 0.012279904447495937, 0.012205724604427814, 0.01218417938798666, 0.012166991829872131, 0.012072664685547352, 0.012108794413506985, 0.012137283571064472, 0.012110652402043343, 0.01213338878005743, 0.011987321078777313, 0.011894487775862217, 0.011856498196721077, 0.011859701946377754, 0.011866775341331959, 0.01180515717715025, 0.011653258465230465, 0.011570349335670471, 0.011719939298927784, 0.011649133637547493, 0.011731145903468132, 0.011479336768388748, 0.01139424555003643, 0.011354350484907627, 0.0113490279763937, 0.011288017965853214, 0.011469380930066109, 0.011489464901387691, 0.011794122867286205, 0.011370549909770489, 0.01108307484537363, 0.011107790283858776, 0.011003301478922367, 0.010934620164334774, 0.010913456790149212, 0.010909306816756725, 0.011027139611542225, 0.01112269051373005, 0.0108859958127141, 0.010724118910729885, 0.010741513222455978, 0.010774058289825916, 0.01059629675000906, 0.01067467499524355, 0.010647148825228214, 0.010632272809743881, 0.01144313532859087, 0.010818900540471077]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sr_pred_train = sr_model.predict(train_data)\n",
        "sr_pred_validation = sr_model.predict(val_data)\n",
        "\n",
        "print(sr_pred_train.shape)\n",
        "print(sr_pred_validation.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "CbbbilZYqOC2",
        "outputId": "2d9df797-780c-4a61-ef3f-c7b78b2d5a42"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 0s 25ms/step\n",
            "56/56 [==============================] - 2s 29ms/step\n",
            "(234, 72, 14, 1)\n",
            "(1766, 72, 14, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dn_model = DNCNN_model()\n",
        "dn_model.summary()\n",
        "dn_model.fit(train_data, train_label, validation_data=(val_data, val_label),shuffle=True, epochs= 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFVNnOnUbiff",
        "outputId": "015345ff-81e9-4a23-c7a5-de858e8b423d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_6 (InputLayer)           [(None, None, None,  0           []                               \n",
            "                                 1)]                                                              \n",
            "                                                                                                  \n",
            " conv2d_66 (Conv2D)             (None, None, None,   640         ['input_6[0][0]']                \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " activation_57 (Activation)     (None, None, None,   0           ['conv2d_66[0][0]']              \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " conv2d_67 (Conv2D)             (None, None, None,   36928       ['activation_57[0][0]']          \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_54 (BatchN  (None, None, None,   256        ['conv2d_67[0][0]']              \n",
            " ormalization)                  64)                                                               \n",
            "                                                                                                  \n",
            " activation_58 (Activation)     (None, None, None,   0           ['batch_normalization_54[0][0]'] \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " conv2d_68 (Conv2D)             (None, None, None,   36928       ['activation_58[0][0]']          \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_55 (BatchN  (None, None, None,   256        ['conv2d_68[0][0]']              \n",
            " ormalization)                  64)                                                               \n",
            "                                                                                                  \n",
            " activation_59 (Activation)     (None, None, None,   0           ['batch_normalization_55[0][0]'] \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " conv2d_69 (Conv2D)             (None, None, None,   36928       ['activation_59[0][0]']          \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_56 (BatchN  (None, None, None,   256        ['conv2d_69[0][0]']              \n",
            " ormalization)                  64)                                                               \n",
            "                                                                                                  \n",
            " activation_60 (Activation)     (None, None, None,   0           ['batch_normalization_56[0][0]'] \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " conv2d_70 (Conv2D)             (None, None, None,   36928       ['activation_60[0][0]']          \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_57 (BatchN  (None, None, None,   256        ['conv2d_70[0][0]']              \n",
            " ormalization)                  64)                                                               \n",
            "                                                                                                  \n",
            " activation_61 (Activation)     (None, None, None,   0           ['batch_normalization_57[0][0]'] \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " conv2d_71 (Conv2D)             (None, None, None,   36928       ['activation_61[0][0]']          \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_58 (BatchN  (None, None, None,   256        ['conv2d_71[0][0]']              \n",
            " ormalization)                  64)                                                               \n",
            "                                                                                                  \n",
            " activation_62 (Activation)     (None, None, None,   0           ['batch_normalization_58[0][0]'] \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " conv2d_72 (Conv2D)             (None, None, None,   36928       ['activation_62[0][0]']          \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_59 (BatchN  (None, None, None,   256        ['conv2d_72[0][0]']              \n",
            " ormalization)                  64)                                                               \n",
            "                                                                                                  \n",
            " activation_63 (Activation)     (None, None, None,   0           ['batch_normalization_59[0][0]'] \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " conv2d_73 (Conv2D)             (None, None, None,   36928       ['activation_63[0][0]']          \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_60 (BatchN  (None, None, None,   256        ['conv2d_73[0][0]']              \n",
            " ormalization)                  64)                                                               \n",
            "                                                                                                  \n",
            " activation_64 (Activation)     (None, None, None,   0           ['batch_normalization_60[0][0]'] \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " conv2d_74 (Conv2D)             (None, None, None,   36928       ['activation_64[0][0]']          \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_61 (BatchN  (None, None, None,   256        ['conv2d_74[0][0]']              \n",
            " ormalization)                  64)                                                               \n",
            "                                                                                                  \n",
            " activation_65 (Activation)     (None, None, None,   0           ['batch_normalization_61[0][0]'] \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " conv2d_75 (Conv2D)             (None, None, None,   36928       ['activation_65[0][0]']          \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_62 (BatchN  (None, None, None,   256        ['conv2d_75[0][0]']              \n",
            " ormalization)                  64)                                                               \n",
            "                                                                                                  \n",
            " activation_66 (Activation)     (None, None, None,   0           ['batch_normalization_62[0][0]'] \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " conv2d_76 (Conv2D)             (None, None, None,   36928       ['activation_66[0][0]']          \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_63 (BatchN  (None, None, None,   256        ['conv2d_76[0][0]']              \n",
            " ormalization)                  64)                                                               \n",
            "                                                                                                  \n",
            " activation_67 (Activation)     (None, None, None,   0           ['batch_normalization_63[0][0]'] \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " conv2d_77 (Conv2D)             (None, None, None,   36928       ['activation_67[0][0]']          \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_64 (BatchN  (None, None, None,   256        ['conv2d_77[0][0]']              \n",
            " ormalization)                  64)                                                               \n",
            "                                                                                                  \n",
            " activation_68 (Activation)     (None, None, None,   0           ['batch_normalization_64[0][0]'] \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " conv2d_78 (Conv2D)             (None, None, None,   36928       ['activation_68[0][0]']          \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_65 (BatchN  (None, None, None,   256        ['conv2d_78[0][0]']              \n",
            " ormalization)                  64)                                                               \n",
            "                                                                                                  \n",
            " activation_69 (Activation)     (None, None, None,   0           ['batch_normalization_65[0][0]'] \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " conv2d_79 (Conv2D)             (None, None, None,   36928       ['activation_69[0][0]']          \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_66 (BatchN  (None, None, None,   256        ['conv2d_79[0][0]']              \n",
            " ormalization)                  64)                                                               \n",
            "                                                                                                  \n",
            " activation_70 (Activation)     (None, None, None,   0           ['batch_normalization_66[0][0]'] \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " conv2d_80 (Conv2D)             (None, None, None,   36928       ['activation_70[0][0]']          \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_67 (BatchN  (None, None, None,   256        ['conv2d_80[0][0]']              \n",
            " ormalization)                  64)                                                               \n",
            "                                                                                                  \n",
            " activation_71 (Activation)     (None, None, None,   0           ['batch_normalization_67[0][0]'] \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " conv2d_81 (Conv2D)             (None, None, None,   36928       ['activation_71[0][0]']          \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_68 (BatchN  (None, None, None,   256        ['conv2d_81[0][0]']              \n",
            " ormalization)                  64)                                                               \n",
            "                                                                                                  \n",
            " activation_72 (Activation)     (None, None, None,   0           ['batch_normalization_68[0][0]'] \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " conv2d_82 (Conv2D)             (None, None, None,   36928       ['activation_72[0][0]']          \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_69 (BatchN  (None, None, None,   256        ['conv2d_82[0][0]']              \n",
            " ormalization)                  64)                                                               \n",
            "                                                                                                  \n",
            " activation_73 (Activation)     (None, None, None,   0           ['batch_normalization_69[0][0]'] \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " conv2d_83 (Conv2D)             (None, None, None,   36928       ['activation_73[0][0]']          \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_70 (BatchN  (None, None, None,   256        ['conv2d_83[0][0]']              \n",
            " ormalization)                  64)                                                               \n",
            "                                                                                                  \n",
            " activation_74 (Activation)     (None, None, None,   0           ['batch_normalization_70[0][0]'] \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " conv2d_84 (Conv2D)             (None, None, None,   36928       ['activation_74[0][0]']          \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_71 (BatchN  (None, None, None,   256        ['conv2d_84[0][0]']              \n",
            " ormalization)                  64)                                                               \n",
            "                                                                                                  \n",
            " activation_75 (Activation)     (None, None, None,   0           ['batch_normalization_71[0][0]'] \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " conv2d_85 (Conv2D)             (None, None, None,   577         ['activation_75[0][0]']          \n",
            "                                1)                                                                \n",
            "                                                                                                  \n",
            " subtract_3 (Subtract)          (None, None, None,   0           ['input_6[0][0]',                \n",
            "                                1)                                'conv2d_85[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 670,529\n",
            "Trainable params: 668,225\n",
            "Non-trainable params: 2,304\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/100\n",
            "8/8 [==============================] - 76s 10s/step - loss: 0.6848 - mean_squared_error: 0.6848 - val_loss: 0.0299 - val_mean_squared_error: 0.0299\n",
            "Epoch 2/100\n",
            "8/8 [==============================] - 74s 10s/step - loss: 0.0499 - mean_squared_error: 0.0499 - val_loss: 0.0300 - val_mean_squared_error: 0.0300\n",
            "Epoch 3/100\n",
            "8/8 [==============================] - 72s 10s/step - loss: 0.0306 - mean_squared_error: 0.0306 - val_loss: 0.0307 - val_mean_squared_error: 0.0307\n",
            "Epoch 4/100\n",
            "8/8 [==============================] - 72s 10s/step - loss: 0.0258 - mean_squared_error: 0.0258 - val_loss: 0.0303 - val_mean_squared_error: 0.0303\n",
            "Epoch 5/100\n",
            "8/8 [==============================] - 74s 10s/step - loss: 0.0225 - mean_squared_error: 0.0225 - val_loss: 0.0305 - val_mean_squared_error: 0.0305\n",
            "Epoch 6/100\n",
            "8/8 [==============================] - 72s 10s/step - loss: 0.0201 - mean_squared_error: 0.0201 - val_loss: 0.0316 - val_mean_squared_error: 0.0316\n",
            "Epoch 7/100\n",
            "8/8 [==============================] - 72s 10s/step - loss: 0.0179 - mean_squared_error: 0.0179 - val_loss: 0.0332 - val_mean_squared_error: 0.0332\n",
            "Epoch 8/100\n",
            "8/8 [==============================] - 74s 10s/step - loss: 0.0162 - mean_squared_error: 0.0162 - val_loss: 0.0340 - val_mean_squared_error: 0.0340\n",
            "Epoch 9/100\n",
            "8/8 [==============================] - 72s 10s/step - loss: 0.0151 - mean_squared_error: 0.0151 - val_loss: 0.0359 - val_mean_squared_error: 0.0359\n",
            "Epoch 10/100\n",
            "8/8 [==============================] - 72s 10s/step - loss: 0.0142 - mean_squared_error: 0.0142 - val_loss: 0.0360 - val_mean_squared_error: 0.0360\n",
            "Epoch 11/100\n",
            "8/8 [==============================] - 74s 10s/step - loss: 0.0137 - mean_squared_error: 0.0137 - val_loss: 0.0363 - val_mean_squared_error: 0.0363\n",
            "Epoch 12/100\n",
            "8/8 [==============================] - 72s 10s/step - loss: 0.0134 - mean_squared_error: 0.0134 - val_loss: 0.0360 - val_mean_squared_error: 0.0360\n",
            "Epoch 13/100\n",
            "8/8 [==============================] - 72s 10s/step - loss: 0.0127 - mean_squared_error: 0.0127 - val_loss: 0.0337 - val_mean_squared_error: 0.0337\n",
            "Epoch 14/100\n",
            "8/8 [==============================] - 74s 10s/step - loss: 0.0120 - mean_squared_error: 0.0120 - val_loss: 0.0336 - val_mean_squared_error: 0.0336\n",
            "Epoch 15/100\n",
            "8/8 [==============================] - 73s 10s/step - loss: 0.0116 - mean_squared_error: 0.0116 - val_loss: 0.0327 - val_mean_squared_error: 0.0327\n",
            "Epoch 16/100\n",
            "8/8 [==============================] - 71s 10s/step - loss: 0.0113 - mean_squared_error: 0.0113 - val_loss: 0.0331 - val_mean_squared_error: 0.0331\n",
            "Epoch 17/100\n",
            "8/8 [==============================] - 74s 10s/step - loss: 0.0112 - mean_squared_error: 0.0112 - val_loss: 0.0313 - val_mean_squared_error: 0.0313\n",
            "Epoch 18/100\n",
            "8/8 [==============================] - 71s 10s/step - loss: 0.0109 - mean_squared_error: 0.0109 - val_loss: 0.0309 - val_mean_squared_error: 0.0309\n",
            "Epoch 19/100\n",
            "8/8 [==============================] - 71s 10s/step - loss: 0.0105 - mean_squared_error: 0.0105 - val_loss: 0.0316 - val_mean_squared_error: 0.0316\n",
            "Epoch 20/100\n",
            "8/8 [==============================] - 73s 10s/step - loss: 0.0105 - mean_squared_error: 0.0105 - val_loss: 0.0302 - val_mean_squared_error: 0.0302\n",
            "Epoch 21/100\n",
            "8/8 [==============================] - 71s 10s/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.0302 - val_mean_squared_error: 0.0302\n",
            "Epoch 22/100\n",
            "8/8 [==============================] - 72s 10s/step - loss: 0.0098 - mean_squared_error: 0.0098 - val_loss: 0.0295 - val_mean_squared_error: 0.0295\n",
            "Epoch 23/100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qiUTEXgGjAJq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}